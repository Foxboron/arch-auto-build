# -*- python -*-
# ex: set filetype=python:

import random

from buildbot.process import remotecommand
from buildbot.plugins import *
from buildbot.plugins import util, steps
from buildbot.process import buildstep, logobserver
from twisted.internet import defer


# This is a sample buildmaster config file. It must be installed as
# 'master.cfg' in your buildmaster's base directory.

# This is the dictionary that the buildmaster pays attention to. We also use
# a shorter alias to save typing.
c = BuildmasterConfig = {}

####### WORKERS

# The 'workers' list defines the set of recognized workers. Each element is
# a Worker object, specifying a unique worker name and password.  The same
# worker name and password must be configured on the worker.
# c['workers'] = [worker.Worker("example-worker", "pass", max_builds=30),
#                 worker.Worker("example-worker2", "pass", max_builds=30)]

workers = ["bot1","bot2"]

c['workers'] = [worker.LocalWorker(bot) for bot in workers]
# 'protocols' contains information about protocols which master will use for
# communicating with workers. You must define at least 'port' option that workers
# could connect to your master with this protocol.
# 'port' must match the value configured into the workers (with their
# --master option)
c['protocols'] = {'pb': {'port': 9989}}

####### CHANGESOURCES

# the 'change_source' setting tells the buildmaster how it should find out
# about source code changes.  Here we point to the buildbot clone of pyflakes.

c['change_source'] = []
c['change_source'].append(changes.GitPoller(
        'git://github.com/Foxboron/PKGBUILDS.git',
        workdir='gitpoller-workdir', branch='master',
        pollinterval=10))

####### SCHEDULERS

# Configure the Schedulers, which decide how to react to incoming changes.  In this
# case, just kick off a 'runtests' build

c['schedulers'] = []
#c['schedulers'].append(schedulers.SingleBranchScheduler(
#                            name="all",
#                            change_filter=util.ChangeFilter(branch='master'),
#                            treeStableTimer=None,
#                            builderNames=["unpack-packages"]))



sch = schedulers.ForceScheduler(
        name="force",
        buttonName="Build package",
        label="Build package",
        builderNames=["unpack-packages"],

        codebases=[
            util.CodebaseParameter(
                "",
                name="Main repository",
                branch=util.ChoiceStringParameter(
                    name="branch",
                    choices=["master"],
                    default="master"),

                revision=util.FixedParameter(name="revision", default=""),
                repository=util.FixedParameter(name="repository", default=""),
                project=util.FixedParameter(name="project", default=""),
                ),
            ],

        properties=[
            util.StringParameter(name="build_package",
                label="Package:", default="",
                required=False, size=80),
            util.StringParameter(name="repository",
                label="Repository:", default="foxboron",
                required=False, size=80),
            ]
    )


c['schedulers'].append(sch)     

c['schedulers'].append(schedulers.Triggerable(name="build", builderNames=["build-package"]))

####### BUILDERS



class TriggerWithPackageNames(steps.Trigger, buildstep.ShellMixin):

    def assign_build_props(self, name, dependencies, worker=False):
        props = self.set_properties.copy()
        props["virtual_builder_name"] = name 
        props["package"] = name 
        props["dependencies"] = dependencies 
        if worker:
            props["workername"] = worker
        return ["build", props]

    def add_build(self, package, needed, worker=False):
        """I was scared for multipe triggers for the same package :c"""
        if package not in self._build_requests:
            self.sp.append(self.assign_build_props(package, needed))

    def resolve(self, name, packages, graph=[]):
        """Poor mans dependency resolver """
        available = list(packages.keys())
        for i in packages[name]:
            if i in available and i not in graph:
                graph.append(i)
                self.resolve(i, packages, graph=graph)
        return graph

    def extract_deps(self, srcinfo):
        """ Poor mans .SRCINFO parser """
        packages={}
        pkgname=""

        for i in srcinfo.split("\n"):
            if not i:
                continue
            if i[0] == "#":
                continue
            option = i.strip() 
            key,value = option.split(" = ")
            if key == "pkgbase":
                pkgname=value
                packages[pkgname] = []
            if key == "makedepends":
                packages[pkgname].append(value)
            if key == "depends":
                packages[pkgname].append(value)
        return packages

    @defer.inlineCallbacks
    def getSchedulersAndProperties(self):
        """Bread and butter.
        This triggers all the needed PKGBUILDS and resolves the dependencies"""
        self.sp = []
        self._build_requests = []

        # If we have dependant builds, they need to go on the same worker
        worker = False


        # I simply dont know how to make the yield stuff recursive
        # so we find all .SRCINFOs available and make a list
        self.observer = logobserver.BufferLogObserver()
        self.addLogObserver('stdio', self.observer)
        cmd = yield self.makeRemoteShellCommand(command="cat */.SRCINFO")
        yield self.runCommand(cmd)
        dependencies = self.extract_deps(self.observer.getStdout())


        # Build all packages
        if self.getProperty("build_package"):
            package = self.getProperty("build_package")
            needed = self.resolve(package, dependencies)
            # Run over all needed packages and find their deps
            for i in needed:
                _needed = self.resolve(i, dependencies)
                self.add_build(i, _needed)
            self.add_build(package, needed)
            return self.sp
       
       # Build all
        if self.getProperty("build_all"):
            for package in dependencies.keys():
                needed = self.resolve(package, dependencies)
                # Run over all needed packages and find their deps
                for i in needed:
                    worker = random.choice(workers)
                    _needed = self.resolve(i, dependencie, worker=worker)
                    self.add_build(i, _needed, worker=worker)
                self.add_build(package, needed, worker=worker)
            return self.sp

        # Only build changes PKGBUILDS
        # And no, i don't know how to remove the output from
        # self.observer :c
        self.observer = logobserver.BufferLogObserver()
        self.addLogObserver('stdio', self.observer)
        cmd = yield self.makeRemoteShellCommand(command=["git", "diff","--name-only","HEAD~1"])
        yield self.runCommand(cmd)

        packages = []
        for i in self.observer.getStdout().split():
            file = i.split("/")[0]
            if file in available_packages: 
                packages.append(file)
    
        # Lets try and find all packages we need to trigger for this
        for package in set(packages):
            needed = self.resolve(package, dependencies)
            # Run over all needed packages and find their deps
            for i in needed:
                worker = random.choice(workers)
                _needed = self.resolve(i, dependencies, worker=worker)
                self.add_build(i, _needed, worker=worker)
            self.add_build(package, needed, worker=worker)
        return self.sp

# The 'builders' list defines the Builders, which tell Buildbot how to perform a build:
# what steps, and which workers can execute them.  Note that any particular build will
# only take place on one worker.

unpack_packages = util.BuildFactory()
unpack_packages.addStep(steps.Git(repourl='git://github.com/Foxboron/PKGBUILDS.git', mode='incremental'))
#unpack_packages.addStep(TriggerWithPackageNames(schedulerNames=['build']))
unpack_packages.addStep(TriggerWithPackageNames(schedulerNames=['build'], waitForFinish=True, updateSourceStamp=True))


build_package = util.BuildFactory()
build_package.addStep(steps.Git(repourl='git://github.com/Foxboron/PKGBUILDS.git', mode='incremental', haltOnFailure=True))

@util.renderer
def makeCommand(props):
    options = {}
    options["pkg"] = props.getProperty('package')
    options["repo"] = props.getProperty('repository')
    # build ="docker run --privileged --rm -v /srv/repo/{repo}:/var/cache/pacman/{repo} -v
    # /srv/buildbot/master/workers/bot1/build-package/build/{pkg}:/aur/{pkg} -v
    # /sys/fs/cgroup/systemd/docker:/sys/fs/cgroup/systemd/docker arch-build /usr/bin/build.sh".format(**options)
    build = "build-package {repo} {pkg}".format(**options)
    return build.split(' ')

build_package.addStep(steps.ShellCommand(command=makeCommand, haltOnFailure=True))

c['builders'] = []
c['builders'].append(
    util.BuilderConfig(name="unpack-packages",
        workernames=[bot for bot in workers],
        factory=unpack_packages))

c['builders'].append(
    util.BuilderConfig(name="build-package",
        collapseRequests=False,
        canStartBuild=util.enforceChosenWorker,
        workernames=[bot for bot in workers],
        factory=build_package,
        properties={"repository": "foxboron"}))

c['services'] = []

c['title'] = "Foxboron Packages"

c['titleURL'] = "https://build.velox.pw"
c['buildbotURL'] = "https://build.velox.pw/"


authz = util.Authz(
  allowRules=[
          util.AnyControlEndpointMatcher(role="admins"),
            ],
roleMatchers=[
        util.RolesFromEmails(admins=["admin"])
          ]
            )
auth=util.UserPasswordAuth({'admin': 'admin'})





c['www'] = dict(port=8010,
                plugins=dict(waterfall_view={}, console_view={}))

#c['www']['auth'] = auth
#c['www']['authz'] = authz

c['db'] = {
    'db_url' : "sqlite:///state.sqlite",
}
